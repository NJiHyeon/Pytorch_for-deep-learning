{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPB2ngaTDo7VOTOtoI8B5WB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "233b27e4826447bc801122b7c79d473d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53516e9c21db4f62baa076d813922f7f",
              "IPY_MODEL_6e36884390794ed98b8a952b2508f37d",
              "IPY_MODEL_282af482743a4bc6b629785d94c9376e"
            ],
            "layout": "IPY_MODEL_d50d9ec6dadf4ce5b6dda65beef560be"
          }
        },
        "53516e9c21db4f62baa076d813922f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045483458b52429a8ae1d4bc9c0b5d77",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad2bee9713a4f6090d4c15a85de1883",
            "value": ""
          }
        },
        "6e36884390794ed98b8a952b2508f37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1108c1246bef4bb2b63d6e6dd6832995",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbda629cace04c8bba1c2055fe1ca19f",
            "value": 170498071
          }
        },
        "282af482743a4bc6b629785d94c9376e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1c9ae4fa564fcdb96b7f9f3ffc2fe6",
            "placeholder": "​",
            "style": "IPY_MODEL_7e821d53fc2e4162984d85a6c8cc374c",
            "value": " 170499072/? [00:02&lt;00:00, 63946504.71it/s]"
          }
        },
        "d50d9ec6dadf4ce5b6dda65beef560be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045483458b52429a8ae1d4bc9c0b5d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad2bee9713a4f6090d4c15a85de1883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1108c1246bef4bb2b63d6e6dd6832995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbda629cace04c8bba1c2055fe1ca19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b1c9ae4fa564fcdb96b7f9f3ffc2fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e821d53fc2e4162984d85a6c8cc374c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NJiHyeon/Pytorch_for-deep-learning/blob/main/CH3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎필요한 모듈 설치 및 설명"
      ],
      "metadata": {
        "id": "xV90GGy-zRhJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3urOqzfUu1l7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tr\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###### - torchvision.transforms는 데이터를 불러오면서 그 다음에 전처리를 바로 할 수 있게 해주는 라이브러리\n",
        "###### - DataLoader는 배치 사이즈 형태로 만들어서 실제로 학습을 할 때 이용할 수 있는 형태를 만들어주는 라이브러리\n",
        "###### - dataset은 튜닝을 할 때 사용"
      ],
      "metadata": {
        "id": "8k-_0QWEu_LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎파이토치 제공 데이터 불러오기"
      ],
      "metadata": {
        "id": "Wq_8Fh54wzuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.transform 정의"
      ],
      "metadata": {
        "id": "RnwpA-IPxEkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transf = tr.Compose([tr.Resize(8), tr.ToTensor()])"
      ],
      "metadata": {
        "id": "DGGvf24LxfYd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###### - Compose : 전처리를 할 때 순서대로 작업을 수행하게 되는 것(위의 같은 경우, 8 by 8fh resize가 되고, 텐서 데이터로 바꿔주는 것)\n",
        "###### -  처음에 들어오는 이미지는 Transforms on PIL Image라고 해서 특정 타입을 말하는 것\n",
        "###### -  종류 : Pad, Grayscale, RandomCrop, Normalize ..\n",
        "###### -  Transforms on torch.*Tensor - tensor image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-AvAcrI-xw50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.data 불러오기"
      ],
      "metadata": {
        "id": "V9HKMQewznbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "233b27e4826447bc801122b7c79d473d",
            "53516e9c21db4f62baa076d813922f7f",
            "6e36884390794ed98b8a952b2508f37d",
            "282af482743a4bc6b629785d94c9376e",
            "d50d9ec6dadf4ce5b6dda65beef560be",
            "045483458b52429a8ae1d4bc9c0b5d77",
            "0ad2bee9713a4f6090d4c15a85de1883",
            "1108c1246bef4bb2b63d6e6dd6832995",
            "bbda629cace04c8bba1c2055fe1ca19f",
            "6b1c9ae4fa564fcdb96b7f9f3ffc2fe6",
            "7e821d53fc2e4162984d85a6c8cc374c"
          ]
        },
        "id": "moFKtK25yHmD",
        "outputId": "73a52dbb-e35b-4d43-ffdc-b435fdf47266"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "233b27e4826447bc801122b7c79d473d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. trainset 확인"
      ],
      "metadata": {
        "id": "BaaKEYo1yZbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[0][0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFzmLIpyyK5n",
        "outputId": "86735507-00c6-4f91-8047-e6eaca1848a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###### - trainset의 size 확인(첫번째꺼만 불러오고 튜플형태로 되어있다.(이미지,레이블))\n",
        "###### - 결과 : 채널 3개에 8 by 8 이미지\n",
        "\n"
      ],
      "metadata": {
        "id": "H9a144ThzXZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. DataLoader를 이용해서 각각을 정의"
      ],
      "metadata": {
        "id": "vAq3gVWpykjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "n2wByyv9yZgs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###### - num_workers는 data를 load할 때 subprocess를 몇개 쓰느냐를 정의\n",
        "###### - 이 단계까지 하면 배치 형태로 모두 분리 해놓은 상태가 된다.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1a7ZvhD-zAxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. trainloader 길이 확인"
      ],
      "metadata": {
        "id": "6D4eG7Qqyptd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SWBGLk60DXP",
        "outputId": "10bac7f5-3ee7-447b-95d7-74eae4f82101"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###### - CIFAR 데이터의 개수가 50000개인데 batch_size가 50이므로 trainloader의 길이가 1000가 된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "a6HRbbvz0PDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. trainloader의 실제 값 확인"
      ],
      "metadata": {
        "id": "vq5aGFTyyu_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "metadata": {
        "id": "8Groh-9K0i1Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###### - 실제 값을 보고 싶을 때 \n",
        "\n"
      ],
      "metadata": {
        "id": "tiKPuN2V0lzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. 마지막으로 사이즈 확인"
      ],
      "metadata": {
        "id": "iO7tLh5gy14Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ6GG5aQ0x_d",
        "outputId": "75400330-18f8-420a-e96d-5d1653cfc152"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###### - 파이토치는 신경망에 들어갈 때 배치사이즈, 채널 수, 이미지 사이즈의 순서로 들어간다. \n"
      ],
      "metadata": {
        "id": "E54ud8YI08ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ transforms, torchvision.sets, DataLoader 3줄이면 끝 "
      ],
      "metadata": {
        "id": "jkV0xBUazzaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RPnXwMNg2IKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎같은 클래스 별 폴더 이미지 데이터 이용\n"
      ],
      "metadata": {
        "id": "IONK2FIC2Iz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ./class/tiger ./class/lion\n",
        "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n",
        "trainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=2)\n",
        "print(len(trainloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "PNq-rlY12XQs",
        "outputId": "351c8c46-9d45-4ae9-b953-ec52d798570f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3a7ed5e1f04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ./class/tiger ./class/lion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtransf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         )\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m     ) -> None:\n\u001b[1;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './class'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - torchvision.datasets.ImageFolder를 이용하면 class안에 있는 이미지들을 알아서 search해주고 각각의 다른 폴더에 대해서 labeling을 자동으로 다르게 매겨준다.\n",
        "###### - 전처리 또한 이용할 수 있다.(transform=transf)\n",
        "###### - trainset= 한줄로 데이터 전체를 모두 불러오면서 레이블이 자동으로 매겨지면서 전처리까지 가능\n"
      ],
      "metadata": {
        "id": "1xtsPzwS5O2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[0][0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7NZ1RIj6q0s",
        "outputId": "0998eb51-07b3-41e5-c830-13731a16d028"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4ukVs_4k6xfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎개인 데이터 사용"
      ],
      "metadata": {
        "id": "hOC1XHQ761Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import preprocessing\n",
        "\n",
        "train_images = np.random.randint(256, size=(20,32,32,3))\n",
        "train_labels = np.random.randint(2, size=(20,1))\n",
        "\n",
        "#preprocessing ...\n",
        "#train_images, train_labels = preprocessing(train_images, train_labels)\n",
        "\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVqrvBhn7oeQ",
        "outputId": "e117acf9-6128-4761-e2e1-01e0d39876ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 32, 32, 3) (20, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorData(Dataset) :\n",
        "  def __init__(self, x_data, y_data) :\n",
        "    self.x_data = torch.FloatTensor(x_data) #tensor 변환(구체적인 tensor)\n",
        "    self.x_data = self.x_data.permute(0,3,1,2)  #이미지 개수, 채널 수, 이미지 너비, 높이 순서 바꾸기\n",
        "    self.y_data = torch.FloatTensor(y_data)\n",
        "    self.len = self.y_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "      return self.x_data[index], self.y_data[index] #__getitem__으로해서 x,y를 튜플형태로\n",
        "\n",
        "  def __len__(self) :\n",
        "    return self.len #데이터 개수 산출"
      ],
      "metadata": {
        "id": "ZuqVmxrp79Dv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - dataset의 class에 대해 상속을 받을 class를 만들기\n",
        "###### - 상속받을 클래스의 이름은 원하는대로 지정"
      ],
      "metadata": {
        "id": "BYsZuzas8BXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorData(train_images, train_labels)\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "train_data[0][0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZki2GMD9bkV",
        "outputId": "d21d1e49-4229-4a7e-da17-b10a84148bff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - class 인스턴스 생성(train_images, train_labels)\n",
        "###### - 데이터가 만들어지면 배치 형태로 만들어야 하니까 DataLoader에 다시 넣어주는 작업 후 사이즈 확인"
      ],
      "metadata": {
        "id": "yG1g6diI9lcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()"
      ],
      "metadata": {
        "id": "BTHJnyqV9j7-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrKmsW9T-NCw",
        "outputId": "e55dc2d7-a506-46d7-94ee-36a2c165a53e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "M56pk8VF_dGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎개인적으로 torchvision.datasets.ImageFolder를 쓰지 않는 이유"
      ],
      "metadata": {
        "id": "3cyfE4jB-g8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - 3줄안에 못 만드는 경우가 있다.\n",
        "###### - 예를 들어 다른 작업에도 쓰는 데이터의 경우와 폴더가 아닌 SQL 같은 곳에서 넘어오는 경우"
      ],
      "metadata": {
        "id": "Q4L3_RpM-tsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FG60C7Rj_bAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎꿀팁 : 수동으로 원하는 전처리를 할 때 클래스 만든다음에 Compose를 이용해서 사용"
      ],
      "metadata": {
        "id": "rkZ8qJj5_gf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#우리가 가지고 있는 데이터를 transform을 이용하려면 아래의 형태를 잘 알아야 한다.(양식)\n",
        "from torch.utils.data import Dataset\n",
        " class MyDataset(Dataset) :\n",
        "  def __init__(self) :\n",
        "  def __getitem__(self, index) :\n",
        "  def __len__(self) :"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "llxU_4fHBmGY",
        "outputId": "6b073db7-aa5a-4b5e-f5cf-4eeb9e0b00e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-78d43f2e0e20>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    class MyDataset(Dataset) :\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset) :\n",
        "  def __init__(self, x_data, y_data, transform=None) :\n",
        "    self.x_data = x_data\n",
        "    self.y_data = y_data\n",
        "    self.transform = transform\n",
        "    self.len = len(y_data)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    sample = self.x_data[index], self.y_data[index] \n",
        "    if self.transform :\n",
        "      sample = self.transform(sample) \n",
        "    return sample\n",
        "\n",
        "  def __len__(self) :\n",
        "    return self.len\n",
        "  \n",
        "\n",
        "class ToTensor :\n",
        "  def __call__(self, sample) :\n",
        "    inputs, labels = sample\n",
        "    inputs = torch.FloatTensor(inputs) \n",
        "    inputs = inputs.permute(2,0,1)\n",
        "    return inputs, torch.LongTensor(labels)\n",
        "\n",
        "\n",
        "class LinearTensor :\n",
        "  def __init__(self, slope=1, bias=0) :\n",
        "    self.slope = slope\n",
        "    self.bias = bias\n",
        "\n",
        "  def __call__(self, sample) :\n",
        "    inputs, labels = sample\n",
        "    inputs = self.slope*inputs + self.bias\n",
        "    return inputs, labels"
      ],
      "metadata": {
        "id": "bUKutjutC9wZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - 이런 식으로 transform에 대해서 쭉 클래스로 만든다. (call함수 이용해서)"
      ],
      "metadata": {
        "id": "PASCZwd5DXBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans = tr.Compose([ToTensor(), LinearTensor(2,5)])\n",
        "ds1 = MyDataset(train_images, train_labels, transform=trans)\n",
        "train_loader1 = DataLoader(ds1, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "lmZXVrLeDwfD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - 그 다음에 사용하는 방법은 똑같다.(Compose지정 - 클래스에 변수 넣기 - Dataloader로 배치 형태로 만들기)\n",
        "###### - 여기서 궁금증 :) tr.ToTensor()안쓰고 일일이 만드나 ? 맨 처음에 말했듯이 transform을 사용하려면 들어오는 데이터가 PIL Image 형태여야 한다. 하지만 우리가 가지고 있는 데이터는 넘파이이므로 타입이 다르기 때문에 tr.ToTensor()을 사용해버리면 에러 발생\n",
        "###### - 그래도 tr을 사용하고 싶다면 ? 돋보기 참고"
      ],
      "metadata": {
        "id": "_KPaV6lADwnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_data = ds1[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBuMsQZbEDf-",
        "outputId": "0b2bb199-6702-430c-9c5b-482b46d46b6e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - 넘파이에서 텐서로 바뀌었다. "
      ],
      "metadata": {
        "id": "E2kv22NuEDnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter1 = iter(train_loader1)\n",
        "images1, labels1 = dataiter1.next()"
      ],
      "metadata": {
        "id": "7YILUVI7EIGo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMGyuGBvGBGl",
        "outputId": "0ff33586-c17f-45a0-aa24-0e7a370ed857"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 75., 103., 341.,  ..., 471., 363., 347.],\n",
              "          [123., 185., 341.,  ..., 393., 325., 501.],\n",
              "          [ 69., 445., 333.,  ..., 269., 173., 497.],\n",
              "          ...,\n",
              "          [289., 243., 505.,  ...,  43.,   9., 299.],\n",
              "          [339., 509., 505.,  ..., 365., 485., 389.],\n",
              "          [439., 319., 323.,  ..., 181., 281., 439.]],\n",
              "\n",
              "         [[333., 151., 259.,  ..., 333., 477., 345.],\n",
              "          [471., 193., 127.,  ..., 455.,  21., 303.],\n",
              "          [ 67., 463., 397.,  ..., 493., 421., 471.],\n",
              "          ...,\n",
              "          [ 49., 475., 399.,  ..., 199., 305., 469.],\n",
              "          [115., 177.,  89.,  ..., 293., 457., 397.],\n",
              "          [391., 385., 311.,  ..., 285., 365., 129.]],\n",
              "\n",
              "         [[447., 459., 507.,  ..., 101., 237., 119.],\n",
              "          [147., 259.,  55.,  ..., 423., 341.,  11.],\n",
              "          [343., 159., 409.,  ..., 479., 461., 367.],\n",
              "          ...,\n",
              "          [159., 419., 263.,  ...,  75., 291., 117.],\n",
              "          [429., 359., 285.,  ..., 289.,  11., 451.],\n",
              "          [ 11., 237., 185.,  ..., 425., 375., 185.]]],\n",
              "\n",
              "\n",
              "        [[[325., 149., 223.,  ..., 399.,  15., 327.],\n",
              "          [251.,  47., 157.,  ..., 177.,  61., 151.],\n",
              "          [467., 493., 229.,  ..., 501., 185., 151.],\n",
              "          ...,\n",
              "          [317., 491., 209.,  ..., 387., 467., 195.],\n",
              "          [353., 471., 115.,  ..., 129., 347., 189.],\n",
              "          [507.,  73., 399.,  ..., 333., 189., 515.]],\n",
              "\n",
              "         [[451.,  97., 183.,  ..., 333., 257., 319.],\n",
              "          [465., 257., 469.,  ..., 137., 325., 293.],\n",
              "          [181., 323., 237.,  ..., 431., 381., 491.],\n",
              "          ...,\n",
              "          [415., 329., 497.,  ..., 435., 343., 433.],\n",
              "          [477.,  69., 173.,  ...,  13., 337., 441.],\n",
              "          [375., 397.,  59.,  ..., 191.,  83., 319.]],\n",
              "\n",
              "         [[215., 497., 251.,  ...,  67., 307., 473.],\n",
              "          [427., 317., 433.,  ..., 189., 373., 133.],\n",
              "          [ 15., 495., 415.,  ...,   7., 103., 465.],\n",
              "          ...,\n",
              "          [255., 123., 401.,  ..., 211., 119., 395.],\n",
              "          [415., 313., 285.,  ..., 263., 387., 337.],\n",
              "          [179., 197., 477.,  ..., 143., 287., 201.]]],\n",
              "\n",
              "\n",
              "        [[[485., 421., 177.,  ..., 429.,  97., 417.],\n",
              "          [457., 247.,  59.,  ..., 101., 413.,  55.],\n",
              "          [203., 337.,   9.,  ...,   9.,  13.,  77.],\n",
              "          ...,\n",
              "          [ 83., 229., 279.,  ...,  63., 397.,  25.],\n",
              "          [ 23.,  95., 201.,  ..., 375.,  91., 479.],\n",
              "          [471.,  29.,  11.,  ..., 275., 117., 141.]],\n",
              "\n",
              "         [[485., 253., 369.,  ..., 253., 423., 227.],\n",
              "          [371., 147., 193.,  ...,  13., 315., 177.],\n",
              "          [441., 337., 417.,  ..., 241., 403., 447.],\n",
              "          ...,\n",
              "          [203., 501., 307.,  ..., 269., 473., 183.],\n",
              "          [331.,  41., 279.,  ...,  31.,   7., 483.],\n",
              "          [411.,  95.,  13.,  ..., 321.,  57., 309.]],\n",
              "\n",
              "         [[ 57., 225., 495.,  ...,  51., 169., 321.],\n",
              "          [455., 109., 505.,  ...,  31., 171., 505.],\n",
              "          [425., 155., 177.,  ..., 395., 419., 369.],\n",
              "          ...,\n",
              "          [419.,  63., 503.,  ..., 371., 383., 417.],\n",
              "          [359., 411., 197.,  ..., 409., 275., 305.],\n",
              "          [383., 413., 493.,  ..., 167., 357., 383.]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[459., 383., 201.,  ..., 195., 425., 243.],\n",
              "          [ 21., 463., 335.,  ..., 321., 293.,  29.],\n",
              "          [339., 423., 313.,  ..., 157., 317.,  29.],\n",
              "          ...,\n",
              "          [131., 373., 241.,  ..., 121., 441., 173.],\n",
              "          [207.,  23., 191.,  ..., 305.,  43., 289.],\n",
              "          [ 17.,  51., 447.,  ..., 417., 343., 227.]],\n",
              "\n",
              "         [[293., 121., 117.,  ..., 263., 269.,  59.],\n",
              "          [175., 479.,  43.,  ..., 123., 333.,  91.],\n",
              "          [493., 145., 417.,  ...,  93., 229., 449.],\n",
              "          ...,\n",
              "          [137., 483., 491.,  ...,  11.,  11., 457.],\n",
              "          [327., 197.,  81.,  ..., 395., 181., 241.],\n",
              "          [477., 141., 109.,  ..., 297.,  51., 369.]],\n",
              "\n",
              "         [[405., 321., 241.,  ..., 487.,  83., 229.],\n",
              "          [125.,  69., 423.,  ..., 513., 467., 401.],\n",
              "          [299., 507.,  57.,  ..., 271., 363., 325.],\n",
              "          ...,\n",
              "          [349., 221., 105.,  ..., 243., 247., 427.],\n",
              "          [327., 495., 119.,  ..., 141., 283., 385.],\n",
              "          [131., 237., 141.,  ..., 511., 155.,   9.]]],\n",
              "\n",
              "\n",
              "        [[[311., 147., 461.,  ..., 283., 483., 203.],\n",
              "          [155., 377., 119.,  ...,  83., 233.,  41.],\n",
              "          [201., 429., 275.,  ..., 185., 301., 315.],\n",
              "          ...,\n",
              "          [ 69., 375.,  57.,  ..., 441., 107., 133.],\n",
              "          [385., 399., 171.,  ..., 203., 503., 349.],\n",
              "          [343., 413.,  35.,  ..., 273., 219., 433.]],\n",
              "\n",
              "         [[425.,  71., 245.,  ..., 475.,  49., 287.],\n",
              "          [483., 427., 403.,  ...,  35., 137., 239.],\n",
              "          [ 19., 511.,  15.,  ..., 515., 319., 449.],\n",
              "          ...,\n",
              "          [345., 407., 437.,  ..., 503., 245., 103.],\n",
              "          [ 21., 433., 329.,  ..., 211., 255.,  31.],\n",
              "          [445., 161., 499.,  ..., 269., 515.,  25.]],\n",
              "\n",
              "         [[151., 215., 211.,  ..., 433., 115., 429.],\n",
              "          [161., 505., 273.,  ..., 425., 231., 197.],\n",
              "          [121., 277., 371.,  ..., 293., 417., 159.],\n",
              "          ...,\n",
              "          [243., 411., 323.,  ...,  33., 223.,  51.],\n",
              "          [255., 129., 383.,  ..., 279., 431., 461.],\n",
              "          [247., 459., 209.,  ..., 429., 501., 217.]]],\n",
              "\n",
              "\n",
              "        [[[189., 333., 301.,  ..., 145., 437., 421.],\n",
              "          [291., 287.,   7.,  ..., 291., 295., 447.],\n",
              "          [ 79., 499.,   5.,  ...,  63., 413., 191.],\n",
              "          ...,\n",
              "          [ 19., 497., 455.,  ..., 141.,  67.,  31.],\n",
              "          [287., 405.,  57.,  ..., 277., 343., 255.],\n",
              "          [177., 263., 227.,  ...,  43., 309., 481.]],\n",
              "\n",
              "         [[367., 293., 315.,  ..., 313.,  25., 447.],\n",
              "          [241., 489., 319.,  ..., 215., 409.,  53.],\n",
              "          [395., 107., 117.,  ...,  41., 347.,  13.],\n",
              "          ...,\n",
              "          [ 53., 475., 333.,  ..., 391., 107.,  15.],\n",
              "          [279., 261., 501.,  ..., 189., 477., 477.],\n",
              "          [483., 167., 409.,  ...,  91., 377., 161.]],\n",
              "\n",
              "         [[ 41., 111., 255.,  ..., 477., 473.,  61.],\n",
              "          [451., 459., 249.,  ..., 383., 143., 397.],\n",
              "          [439., 343.,  21.,  ...,  75.,   7., 151.],\n",
              "          ...,\n",
              "          [313., 123., 221.,  ..., 195.,  41., 123.],\n",
              "          [471., 307., 313.,  ..., 151., 387.,  31.],\n",
              "          [169., 415., 265.,  ..., 365., 155., 327.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - 값 확인\n",
        "###### - 원래 데이터는 255까지 있는데 2*5가 더해져서 255가 넘는 숫자들이 있다.(계산이 잘 된 것 같다.)\n",
        "###### - 이런식으로 수동으로 원하는 전처리에 대해서 다 클래스를 만든 다음에 compose를 이용해서 사용"
      ],
      "metadata": {
        "id": "4bxb6ZXREIWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RQkxvajtyAq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎tr을 꼭 사용하고 싶다면 ?"
      ],
      "metadata": {
        "id": "a4QFN43uG1xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MyDataset을 먼저 똑같이 만든다.\n",
        "class MyDataset(Dataset) :\n",
        "  def __init__(self, x_data, y_data, transform=None) :\n",
        "    self.x_data = x_data\n",
        "    self.y_data = y_data\n",
        "    self.transform = transform\n",
        "    self.len = len(y_data)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    sample = self.x_data[index], self.y_data[index] \n",
        "    if self.transform :\n",
        "      sample = self.transform(sample) \n",
        "    return sample\n",
        "\n",
        "  def __len__(self) :\n",
        "    return self.len\n",
        "\n",
        "class MyTransform :\n",
        "  def __call__(self, sample) :\n",
        "    inputs, labels = sample\n",
        "    inputs = torch.FloatTensor(inputs)\n",
        "    inputs = inputs.permute(2,0,1)\n",
        "    labels = torch.FloatTensor(labels)\n",
        "\n",
        "    transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor(), tr.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "    final_output = transf(inputs)\n",
        "\n",
        "    return final_output, labels"
      ],
      "metadata": {
        "id": "VY2fpE83tbTS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds2 = MyDataset(train_images, train_labels, transform=MyTransform())\n",
        "train_loader2 = DataLoader(ds2, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "RzdNNKBcuk2i"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### - batch_size를 사용하는 이유 : 학습 때 전체 데이터를 사용하면 너무 느리기 때문에 배치를 나눠서 일부분의 데이터만 넣어서 학습 "
      ],
      "metadata": {
        "id": "2Pvc4MzNvCjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_data = ds2[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjgCjbFEu2ro",
        "outputId": "69478a36-4045-487a-a5e0-d46a1e2acd0a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter2 = iter(train_loader2)\n",
        "images2, labels2 = dataiter2.next()"
      ],
      "metadata": {
        "id": "4J5ky7rSvYfw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images2.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fheoH0vtvhC_",
        "outputId": "f0083e2d-4a39-4f6e-fab5-f4cc72e09ccb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 128, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}